"""
è®­ç»ƒGCNåˆ†ç±»æ¨¡å‹ (é—®é¢˜1)
GCN + Transformeræ¶æ„ç”¨äºæ®‹æŸåˆ†ç±»
"""
import torch
import torch.nn as nn
import torch.optim as optim
from torch_geometric.loader import DataLoader
from pathlib import Path
import json
from tqdm import tqdm
import numpy as np
from datetime import datetime
from sklearn.metrics import (
    precision_score, 
    recall_score, 
    f1_score, 
    roc_auc_score,
    confusion_matrix,
    balanced_accuracy_score,
    matthews_corrcoef,
    cohen_kappa_score
)

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from models.models import GCNTransformerClassifier
from preprocessing.create_dataset import ContainerGraphDataset


class Trainer:
    """GCNåˆ†ç±»æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(
        self,
        model,
        train_loader,
        val_loader,
        device,
        learning_rate=1e-3,
        weight_decay=1e-4,
        save_dir='checkpoints'
    ):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        å‚æ•°:
            model: æ¨¡å‹å®ä¾‹
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            device: è®¾å¤‡ (cuda/cpu)
            learning_rate: å­¦ä¹ ç‡
            weight_decay: æƒé‡è¡°å‡
            save_dir: æ¨¡å‹ä¿å­˜ç›®å½•
        """
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        
        # ä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='max',
            factor=0.5,
            patience=5
        )
        
        # æŸå¤±å‡½æ•°
        self.criterion = nn.CrossEntropyLoss()
        
        # ä¿å­˜ç›®å½•
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(exist_ok=True)
        
        # è®­ç»ƒå†å² - æ·»åŠ æ›´å¤šè¯„ä¼°æŒ‡æ ‡
        self.history = {
            'train_loss': [],
            'train_acc': [],
            'train_f1': [],
            'val_loss': [],
            'val_acc': [],
            'val_f1': [],
            'val_precision': [],
            'val_recall': [],
            'val_auc': [],
            'val_balanced_acc': [],
            'val_mcc': [],
            'val_kappa': [],
            'learning_rate': []
        }
        
        self.best_val_acc = 0.0
        self.best_val_f1 = 0.0
    
    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        total_loss = 0
        all_preds = []
        all_labels = []
        
        pbar = tqdm(self.train_loader, desc='è®­ç»ƒ')
        
        for batch in pbar:
            batch = batch.to(self.device)
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            logits = self.model(batch)
            loss = self.criterion(logits, batch.y)
            
            # åå‘ä¼ æ’­
            loss.backward()
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item() * batch.num_graphs
            pred = logits.argmax(dim=1)
            all_preds.extend(pred.cpu().numpy())
            all_labels.extend(batch.y.cpu().numpy())
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({'loss': f'{loss.item():.4f}'})
        
        # è®¡ç®—æŒ‡æ ‡
        all_preds = np.array(all_preds)
        all_labels = np.array(all_labels)
        
        avg_loss = total_loss / len(all_labels)
        avg_acc = (all_preds == all_labels).mean()
        
        # è®¡ç®—F1ï¼šå•ç±»åˆ«æ—¶ä¹Ÿè®¡ç®—è¯¥ç±»åˆ«çš„F1
        unique_labels = np.unique(all_labels)
        if len(unique_labels) >= 2:
            avg_f1 = f1_score(all_labels, all_preds, average='binary', zero_division=0)
        else:
            # ä»…æœ‰ä¸€ä¸ªç±»åˆ«æ—¶ï¼ŒæŒ‰è¯¥ç±»åˆ«ä½œä¸ºæ­£ç±»è®¡ç®—F1
            pos = int(unique_labels[0])
            try:
                avg_f1 = f1_score(all_labels, all_preds, average='binary', pos_label=pos, zero_division=0)
            except Exception:
                avg_f1 = 0.0
        
        return avg_loss, avg_acc, avg_f1
    
    @torch.no_grad()
    def validate(self):
        """éªŒè¯æ¨¡å‹ - æ·»åŠ å®Œæ•´è¯„ä¼°æŒ‡æ ‡"""
        self.model.eval()
        
        total_loss = 0
        all_preds = []
        all_labels = []
        all_probs = []
        
        pbar = tqdm(self.val_loader, desc='éªŒè¯')
        
        for batch in pbar:
            batch = batch.to(self.device)
            
            # å‰å‘ä¼ æ’­
            logits = self.model(batch)
            loss = self.criterion(logits, batch.y)
            
            # ç»Ÿè®¡
            total_loss += loss.item() * batch.num_graphs
            
            # é¢„æµ‹
            probs = torch.softmax(logits, dim=1)
            pred = logits.argmax(dim=1)
            
            all_preds.extend(pred.cpu().numpy())
            all_labels.extend(batch.y.cpu().numpy())
            all_probs.extend(probs[:, 1].cpu().numpy())
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({'loss': f'{loss.item():.4f}'})
        
        # è®¡ç®—åŸºç¡€æŒ‡æ ‡
        all_preds = np.array(all_preds)
        all_labels = np.array(all_labels)
        all_probs = np.array(all_probs)
        
        avg_loss = total_loss / len(all_labels)
        avg_acc = (all_preds == all_labels).mean()
        
        # æ£€æŸ¥ç±»åˆ«æ•°é‡
        unique_labels = np.unique(all_labels)
        
        # åˆå§‹åŒ–æŒ‡æ ‡
        metrics = {
            'precision': 0.0,
            'recall': 0.0,
            'f1': 0.0,
            'auc': 0.0,
            'balanced_acc': 0.0,
            'mcc': 0.0,
            'kappa': 0.0
        }
        
        # å¦‚æœæœ‰ä¸¤ä¸ªç±»åˆ«ï¼Œè®¡ç®—å®Œæ•´æŒ‡æ ‡
        if len(unique_labels) >= 2:
            try:
                metrics['precision'] = precision_score(all_labels, all_preds, average='binary', zero_division=0)
                metrics['recall'] = recall_score(all_labels, all_preds, average='binary', zero_division=0)
                metrics['f1'] = f1_score(all_labels, all_preds, average='binary', zero_division=0)
                metrics['balanced_acc'] = balanced_accuracy_score(all_labels, all_preds)
                metrics['mcc'] = matthews_corrcoef(all_labels, all_preds)
                metrics['kappa'] = cohen_kappa_score(all_labels, all_preds)
                metrics['auc'] = roc_auc_score(all_labels, all_probs)
            except Exception as e:
                print(f"\nâš ï¸ è­¦å‘Š: éƒ¨åˆ†æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        else:
            # ä»…ä¸€ä¸ªç±»åˆ«æ—¶ï¼ŒæŒ‰è¯¥ç±»åˆ«ä½œä¸ºæ­£ç±»è®¡ç®—P/R/F1ï¼Œå¹¶ç»™å‡ºè¯´æ˜
            pos = int(unique_labels[0])
            try:
                metrics['precision'] = precision_score(all_labels, all_preds, pos_label=pos, average='binary', zero_division=0)
                metrics['recall'] = recall_score(all_labels, all_preds, pos_label=pos, average='binary', zero_division=0)
                metrics['f1'] = f1_score(all_labels, all_preds, pos_label=pos, average='binary', zero_division=0)
            except Exception as e:
                print(f"\nâš ï¸ å•ç±»åˆ«è¯„ä¼°è®¡ç®—å¤±è´¥: {e}")
            # å•ç±»åˆ«æ²¡æœ‰è´Ÿç±»ï¼ŒBalanced Accuracy é€€åŒ–ä¸ºè¯¥ç±»åˆ«çš„å¬å›ç‡
            metrics['balanced_acc'] = metrics['recall']
            # AUC/MCC/Kappa åœ¨å•ç±»åˆ«ä¸‹ä¸å¯è®¡ç®—ï¼Œä¿æŒä¸º0å¹¶æç¤º
            print("\nâ„¹ï¸ æç¤º: éªŒè¯é›†ä¸­ä»…åŒ…å«ä¸€ä¸ªç±»åˆ«ï¼ŒAUC/MCC/Kappa æ— æ³•è®¡ç®—ï¼Œå·²ç½®ä¸º0.0ï¼›Balanced Accuracy=è¯¥ç±»åˆ«å¬å›ç‡ã€‚")
        
        # æ‰“å°è¯¦ç»†è¯„ä¼°æŠ¥å‘Š
        print(f"\n" + "="*70)
        print(f"ğŸ“Š éªŒè¯é›†è¯„ä¼°æŠ¥å‘Š:")
        print(f"="*70)
        print(f"\nã€åŸºç¡€æŒ‡æ ‡ã€‘")
        print(f"  æ€»æ ·æœ¬æ•°: {len(all_labels)}")
        print(f"  å‡†ç¡®ç‡ (Accuracy): {avg_acc:.4f}")
        print(f"  å¹³è¡¡å‡†ç¡®ç‡ (Balanced Accuracy): {metrics['balanced_acc']:.4f}")
        
        print(f"\nã€åˆ†ç±»æ€§èƒ½ã€‘")
        print(f"  ç²¾ç¡®ç‡ (Precision): {metrics['precision']:.4f}")
        print(f"  å¬å›ç‡ (Recall): {metrics['recall']:.4f}")
        print(f"  F1åˆ†æ•° (F1-Score): {metrics['f1']:.4f}")
        
        print(f"\nã€é«˜çº§æŒ‡æ ‡ã€‘")
        print(f"  AUC-ROC: {metrics['auc']:.4f}")
        print(f"  Matthewsç›¸å…³ç³»æ•° (MCC): {metrics['mcc']:.4f}")
        print(f"  Cohen's Kappa: {metrics['kappa']:.4f}")
        
        # æ··æ·†çŸ©é˜µ
        if len(unique_labels) >= 2:
            cm = confusion_matrix(all_labels, all_preds)
            print(f"\nã€æ··æ·†çŸ©é˜µã€‘")
            print(f"  çœŸå®\\é¢„æµ‹    ç±»åˆ«0    ç±»åˆ«1")
            for i, row in enumerate(cm):
                print(f"  ç±»åˆ«{i}      {row[0]:6d}  {row[1]:6d}")
        
        # æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†ç»Ÿè®¡ (ä¿ç•™ç¡¬ç¼–ç å¾ªç¯ä»¥é€‚åº”å•ç±»åˆ«æƒ…å†µ)
        print(f"\nã€ç±»åˆ«æ€§èƒ½ã€‘")
        for cls in [0, 1]:
            mask = (all_labels == cls)
            if mask.sum() > 0:  # åªæœ‰å½“è¯¥ç±»åˆ«å­˜åœ¨æ—¶æ‰æ‰“å°
                cls_acc = (all_preds[mask] == cls).sum() / mask.sum()
                cls_name = "æ— æ®‹æŸ" if cls == 0 else "æœ‰æ®‹æŸ"
                cls_count = mask.sum()
                cls_correct = (all_preds[mask] == cls).sum()
                print(f"  {cls_name} (ç±»åˆ«{cls}): {cls_count} æ ·æœ¬, "
                      f"æ­£ç¡® {cls_correct}, å‡†ç¡®ç‡ {cls_acc:.4f}")
        
        print(f"="*70 + "\n")
        
        return avg_loss, avg_acc, metrics
    
    def train(self, num_epochs):
        """
        è®­ç»ƒæ¨¡å‹
        
        å‚æ•°:
            num_epochs: è®­ç»ƒè½®æ•°
        """
        print("=" * 60)
        print("å¼€å§‹è®­ç»ƒGCNåˆ†ç±»æ¨¡å‹")
        print("=" * 60)
        print(f"è®¾å¤‡: {self.device}")
        print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(self.train_loader)}")
        print(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(self.val_loader)}")
        print(f"æ€»è½®æ•°: {num_epochs}")
        print("=" * 60)
        
        for epoch in range(1, num_epochs + 1):
            print(f"\nEpoch {epoch}/{num_epochs}")
            print("-" * 60)
            
            # è®­ç»ƒ
            train_loss, train_acc, train_f1 = self.train_epoch()
            
            # éªŒè¯
            val_loss, val_acc, val_metrics = self.validate()
            
            # æ›´æ–°å­¦ä¹ ç‡ (åŸºäºF1åˆ†æ•°)
            self.scheduler.step(val_metrics['f1'])
            
            # è®°å½•å†å²
            self.history['train_loss'].append(train_loss)
            self.history['train_acc'].append(train_acc)
            self.history['train_f1'].append(train_f1)
            self.history['val_loss'].append(val_loss)
            self.history['val_acc'].append(val_acc)
            self.history['val_f1'].append(val_metrics['f1'])
            self.history['val_precision'].append(val_metrics['precision'])
            self.history['val_recall'].append(val_metrics['recall'])
            self.history['val_auc'].append(val_metrics['auc'])
            self.history['val_balanced_acc'].append(val_metrics['balanced_acc'])
            self.history['val_mcc'].append(val_metrics['mcc'])
            self.history['val_kappa'].append(val_metrics['kappa'])
            self.history['learning_rate'].append(self.optimizer.param_groups[0]['lr'])
            
            # æ‰“å°ç»Ÿè®¡
            print(f"\nğŸ“ˆ Epoch {epoch} ç»“æœæ‘˜è¦:")
            print(f"  ã€è®­ç»ƒé›†ã€‘")
            print(f"    Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}")
            print(f"  ã€éªŒè¯é›†ã€‘")
            print(f"    Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_metrics['f1']:.4f}")
            print(f"    AUC: {val_metrics['auc']:.4f}, MCC: {val_metrics['mcc']:.4f}, Kappa: {val_metrics['kappa']:.4f}")
            print(f"  ã€å­¦ä¹ çŠ¶æ€ã€‘")
            print(f"    å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.6f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹ (åŸºäºF1åˆ†æ•°)
            if val_metrics['f1'] > self.best_val_f1:
                self.best_val_f1 = val_metrics['f1']
                self.best_val_acc = val_acc
                self.save_checkpoint(epoch, is_best=True)
                print(f"  âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (F1: {val_metrics['f1']:.4f}, Acc: {val_acc:.4f})")
            
            # å®šæœŸä¿å­˜
            if epoch % 10 == 0:
                self.save_checkpoint(epoch, is_best=False)
        
        print("\n" + "=" * 60)
        print("âœ… è®­ç»ƒå®Œæˆ!")
        print("=" * 60)
        print(f"ğŸ“Š æœ€ä½³æ€§èƒ½æŒ‡æ ‡:")
        print(f"  æœ€ä½³éªŒè¯F1: {self.best_val_f1:.4f}")
        print(f"  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_val_acc:.4f}")
        print("=" * 60)
        
        # ä¿å­˜è®­ç»ƒå†å²
        self.save_history()
    
    def save_checkpoint(self, epoch, is_best=False):
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_val_acc': self.best_val_acc,
            'best_val_f1': self.best_val_f1,
            'history': self.history
        }
        
        if is_best:
            path = self.save_dir / 'best_model.pth'
        else:
            path = self.save_dir / f'checkpoint_epoch_{epoch}.pth'
        
        torch.save(checkpoint, path)
    
    def save_history(self):
        """ä¿å­˜è®­ç»ƒå†å²"""
        history_path = self.save_dir / 'training_history.json'
        with open(history_path, 'w', encoding='utf-8') as f:
            json.dump(self.history, f, indent=2)
        
        print(f"è®­ç»ƒå†å²å·²ä¿å­˜: {history_path}")


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½® - ä½¿ç”¨ç›¸å¯¹è·¯å¾„
    config = {
        'data_root': Path(__file__).parent.parent / 'preprocessed',
        'batch_size': 24,  # å¢å¤§æ‰¹æ¬¡ï¼Œå……åˆ†åˆ©ç”¨6GBæ˜¾å­˜
        'num_epochs': 100,  # å¢åŠ è®­ç»ƒè½®æ•°ä»¥å……åˆ†è®­ç»ƒ
        'learning_rate': 5e-4,  # é€‚ä¸­çš„å­¦ä¹ ç‡
        'weight_decay': 5e-4,  # æ­£åˆ™åŒ–æƒé‡
        'hidden_dim': 256,  # ä¿æŒå¹³è¡¡çš„éšè—ç»´åº¦
        'gcn_layers': 3,  # GCNå±‚æ•°
        'num_heads': 8,  # æ³¨æ„åŠ›å¤´æ•°
        'num_transformer_layers': 2,  # Transformerå±‚æ•°
        'dropout': 0.5,  # å¢åŠ dropouté˜²æ­¢è¿‡æ‹Ÿåˆ
        'num_workers': 6,  # ä½¿ç”¨6ä¸ªworkerå……åˆ†åˆ©ç”¨CPU (16æ ¸çš„1/3å·¦å³)
        'save_dir': 'checkpoints_classifier'
    }
    
    # è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        print(f"  GPUå‹å·: {torch.cuda.get_device_name(0)}")
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"  æ˜¾å­˜å®¹é‡: {total_memory:.2f} GB")
        print(f"  CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"  PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        # CUDAæ€§èƒ½ä¼˜åŒ–è®¾ç½®
        torch.backends.cudnn.benchmark = True  # è‡ªåŠ¨å¯»æ‰¾æœ€ä¼˜ç®—æ³•
        torch.backends.cudnn.deterministic = False  # å…è®¸éç¡®å®šæ€§ä»¥æé€Ÿ
        torch.cuda.empty_cache()  # æ¸…ç†æ˜¾å­˜ç¼“å­˜
    
    import multiprocessing
    cpu_count = multiprocessing.cpu_count()
    print(f"  CPUæ ¸å¿ƒæ•°: {cpu_count}")
    print(f"  ä½¿ç”¨Workers: {config['num_workers']}")
    
    print(f"\nâš™ï¸  è®­ç»ƒé…ç½®:")
    print(f"  æ‰¹æ¬¡å¤§å°: {config['batch_size']}")
    print(f"  æœ€å¤§è½®æ•°: {config['num_epochs']}")
    print(f"  å­¦ä¹ ç‡: {config['learning_rate']}")
    print(f"  Dropout: {config['dropout']}")
    print("=" * 80)
    
    # åˆ›å»ºæ•°æ®é›†
    print("\nåŠ è½½æ•°æ®é›†...")
    
    # ä½¿ç”¨å·²åˆ’åˆ†çš„è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_dataset = ContainerGraphDataset(root=config['data_root'], split='train')
    val_dataset = ContainerGraphDataset(root=config['data_root'], split='val')
    
    print(f"è®­ç»ƒé›†: {len(train_dataset)} ä¸ªå›¾")
    print(f"éªŒè¯é›†: {len(val_dataset)} ä¸ªå›¾")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=config['num_workers'],
        pin_memory=True if torch.cuda.is_available() else False,
        persistent_workers=True if config['num_workers'] > 0 else False,  # ä¿æŒworkersæ´»è·ƒ
        prefetch_factor=2 if config['num_workers'] > 0 else None  # é¢„å–æ•°æ®
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'] * 2,  # éªŒè¯æ—¶å¯ä»¥ç”¨æ›´å¤§çš„batch
        shuffle=False,
        num_workers=config['num_workers'],
        pin_memory=True if torch.cuda.is_available() else False,
        persistent_workers=True if config['num_workers'] > 0 else False,
        prefetch_factor=2 if config['num_workers'] > 0 else None
    )
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    model = GCNTransformerClassifier(
        node_features=2048,
        hidden_dim=config['hidden_dim'],
        gcn_layers=config['gcn_layers'],
        num_heads=config['num_heads'],
        num_transformer_layers=config['num_transformer_layers'],
        num_classes=2,
        dropout=config['dropout']
    )
    
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"æ¨¡å‹å‚æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # ä¿å­˜é…ç½®
    save_dir = Path(config['save_dir'])
    save_dir.mkdir(exist_ok=True)
    
    # å°†Pathå¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿JSONåºåˆ—åŒ–
    config_to_save = {k: str(v) if isinstance(v, Path) else v for k, v in config.items()}
    
    config_path = save_dir / 'config.json'
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config_to_save, f, indent=2, ensure_ascii=False)
    
    print(f"é…ç½®å·²ä¿å­˜: {config_path}")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        device=device,
        learning_rate=config['learning_rate'],
        weight_decay=config['weight_decay'],
        save_dir=config['save_dir']
    )
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train(num_epochs=config['num_epochs'])


if __name__ == "__main__":
    main()
